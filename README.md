# ðŸ’¸ Credit Underwriting Hackathon â€“ Teen Titans Submission

Welcome to our submission for the **Credit Underwriting Innovation Hackathon**. Our system is designed to estimate income and repayment capability of financially underserved individuals using non-banking, privacy-compliant data sources. Built with an emphasis on modularity, explainability, and real-world deployability.

---

## ðŸš€ Project Overview

### ðŸŽ¯ Objective

To predict an individualâ€™s creditworthiness in the absence of formal income declarations by leveraging publicly available features and constructing a two-stage machine learning model.

---

## ðŸ§  Solution Architecture

### ðŸ”¹ Stage 1: EMI to Income Proxy Estimator
- **Goal**: Predict `emi_to_income` as a proxy for income using non-sensitive, publicly observable features.
- **Model**: `CatBoostRegressor` trained on synthetic EMI and alternate data.
- **Input Features**: Region, employment patterns, loan counts, balance-to-limit ratios, etc.

### ðŸ”¹ Stage 2: Final Income Predictor
- **Goal**: Use predicted `emi_to_income` + engineered financial features to predict `target_income`.
- **Model**: `CatBoostRegressor` fine-tuned on aligned features with robust validation.
- **Safety**: No use of personally identifiable or directly declared income data.

---

## ðŸ”§ Setup Instructions

### ðŸ–¥ï¸ Environment Setup

Install dependencies using:

```bash
pip install -r requirements.txt

# ðŸ¦ Credit Underwriting Model

A machine learning pipeline to estimate EMI-to-Income ratio and underwrite credit applicants using bureau data.  
Developed during **[Hackathon Name]** by **Team: Teen Titans**  
**Lead Developer & Model Architect**: Kanishka Kumar Singh

---

## ðŸ“ Directory Structure

Credit_UnderWriting_Model/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ bureau_data_10000_without_target.csv
â”‚ â”œâ”€â”€ participant_col_mapping.csv
â”œâ”€â”€ outputs/
â”‚ â””â”€â”€ final_predictions.csv
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ catboost_model.pkl
â”‚ â””â”€â”€ emi_to_income_proxy_model.pkl
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ train_proxy_model.py
â”‚ â”œâ”€â”€ train_main_model.py
â”‚ â””â”€â”€ run_inference.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## ðŸ“Š Evaluation Metrics

| Model Stage   | Metric   | Value               |
|---------------|----------|---------------------|
| Proxy Model   | RMSE     | ~0.00003            |
| Final Model   | RÂ² Score | ~0.38â€“0.42 (varied) |

> âš ï¸ **Note**: Accuracy degraded on blind test due to schema drift and noisy categorical encodings.

---

## ðŸ§© Key Features Engineered

- `debt_to_credit`: Ratio of outstanding debt to credit limit.
- `pin_region`: First two digits of pin code to map regional economics.
- `count_features`: Total active accounts, limits, balances.

---

## ðŸ” Explainability

Used SHAP (SHapley Additive exPlanations) for interpreting model predictions.

```python
import shap
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_sample)
shap.summary_plot(shap_values, X_sample)

## ðŸ§ª Run Inference

To generate predictions:

```bash
python scripts/run_inference.py

## **Steps performed:**

- Loads test CSV and applies preprocessing  
- Predicts `emi_to_income` using proxy model  
- Applies imputations and final prediction  
- Saves output to `outputs/final_predictions.csv`

---

## âš–ï¸ Ethical Compliance

- âœ… No personal income data used  
- âœ… No user-identifiable information  
- âœ… Focused on transparency and fairness

---

## ðŸ‘¨â€ðŸ’» Team

- **Kanishka Kumar Singh** â€“ Lead ML Developer & Model Architect  
- **Varun Kant** - Frontend Developer
- **Pranjal Agarwal** - Lead Developer
- **Naman Jaju** - Backend Developer

---

## ðŸ™ Acknowledgements

- Organized by: **[LenDenClub]**  
- Dataset provided by: **[LenDenCLub]**  
- Special thanks to mentors, professors, and open-source contributors â¤ï¸

---

## ðŸ“Œ Lessons Learned

- **Data quality > model complexity**  
- **Pipeline alignment & categorical consistency are critical**  
- **SHAP is ðŸ”¥ for debugging blind spots**  
- And most importantlyâ€¦ **sleep is underrated ðŸ˜´**

---

## ðŸ“Ž Appendix

- All required packages listed in `requirements.txt`  
  (e.g., CatBoost, SHAP, pandas, NumPy, etc.)
- Trained models saved using `joblib` format in the `models/` directory